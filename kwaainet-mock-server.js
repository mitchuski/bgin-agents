// =====================================
// KwaaiNet Mock Server
// Simulates OpenAI-compatible API for testing
// =====================================

const express = require('express');
const cors = require('cors');
const app = express();
const PORT = 8000;

// Middleware
app.use(cors());
app.use(express.json());

// Mock models endpoint
app.get('/v1/models', (req, res) => {
  res.json({
    object: 'list',
    data: [
      {
        id: 'kwaainet/llama-3.2-3b-instruct',
        object: 'model',
        created: Date.now(),
        owned_by: 'kwaainet'
      },
      {
        id: 'kwaainet/llama-3.2-70b-instruct',
        object: 'model',
        created: Date.now(),
        owned_by: 'kwaainet'
      }
    ]
  });
});

// Mock chat completions endpoint
app.post('/v1/chat/completions', (req, res) => {
  const { messages, model = 'kwaainet/llama-3.2-3b-instruct', max_tokens = 1000, temperature = 0.7 } = req.body;
  
  // Extract the last user message
  const lastMessage = messages[messages.length - 1];
  const userContent = lastMessage?.content || 'Hello';
  
  // Generate a mock response based on the content
  const mockResponse = generateMockResponse(userContent, model);
  
  res.json({
    id: `chatcmpl-${Date.now()}`,
    object: 'chat.completion',
    created: Date.now(),
    model: model,
    choices: [
      {
        index: 0,
        message: {
          role: 'assistant',
          content: mockResponse
        },
        finish_reason: 'stop'
      }
    ],
    usage: {
      prompt_tokens: Math.floor(userContent.length / 4),
      completion_tokens: Math.floor(mockResponse.length / 4),
      total_tokens: Math.floor((userContent.length + mockResponse.length) / 4)
    }
  });
});

// Mock embeddings endpoint
app.post('/v1/embeddings', (req, res) => {
  const { input, model = 'kwaainet/text-embedding-3-small' } = req.body;
  
  // Generate mock embeddings (1536 dimensions)
  const embedding = Array.from({ length: 1536 }, () => Math.random() * 2 - 1);
  
  res.json({
    object: 'list',
    data: [
      {
        object: 'embedding',
        index: 0,
        embedding: embedding
      }
    ],
    model: model,
    usage: {
      prompt_tokens: Math.floor(input.length / 4),
      total_tokens: Math.floor(input.length / 4)
    }
  });
});

// Health check endpoint
app.get('/health', (req, res) => {
  res.json({
    status: 'healthy',
    service: 'kwaainet-mock',
    timestamp: new Date().toISOString(),
    version: '1.0.0'
  });
});

// Generate mock response based on content
function generateMockResponse(userContent, model) {
  const responses = {
    'hello': 'Hello! I\'m the KwaaiNet mock server. I\'m here to help you test the BGIN AI MVP integration. How can I assist you today?',
    'test': 'This is a test response from the KwaaiNet mock server. The integration is working correctly!',
    'blockchain': 'Blockchain governance is a fascinating topic. The BGIN (Blockchain Governance Initiative Network) focuses on developing standards and best practices for decentralized governance systems. Key areas include regulatory compliance, technical standards, privacy rights, and cross-chain governance.',
    'governance': 'Governance in blockchain systems involves decision-making processes, stakeholder participation, and the establishment of rules and standards. BGIN works to create frameworks that balance decentralization with effective governance mechanisms.',
    'privacy': 'Privacy is a fundamental concern in blockchain systems. BGIN addresses privacy rights through selective disclosure mechanisms, zero-knowledge proofs, and privacy-preserving analytics while maintaining transparency where needed.',
    'default': `I understand you're asking about: "${userContent}". This is a mock response from the KwaaiNet server (${model}). In a real implementation, this would be processed by the actual KwaaiNet distributed inference network using Petals technology. The response would be generated by the collaborative efforts of multiple nodes in the network, providing privacy-preserving AI capabilities.`
  };
  
  const lowerContent = userContent.toLowerCase();
  
  if (lowerContent.includes('hello') || lowerContent.includes('hi')) {
    return responses.hello;
  } else if (lowerContent.includes('test')) {
    return responses.test;
  } else if (lowerContent.includes('blockchain')) {
    return responses.blockchain;
  } else if (lowerContent.includes('governance')) {
    return responses.governance;
  } else if (lowerContent.includes('privacy')) {
    return responses.privacy;
  } else {
    return responses.default;
  }
}

// Start server
app.listen(PORT, () => {
  console.log(`ğŸŒ KwaaiNet Mock Server running on port ${PORT}`);
  console.log(`ğŸ“¡ OpenAI-compatible API: http://localhost:${PORT}/v1`);
  console.log(`ğŸ” Health check: http://localhost:${PORT}/health`);
  console.log(`ğŸ“‹ Models: http://localhost:${PORT}/v1/models`);
  console.log(`\nğŸ¤– Ready to serve mock LLM requests for BGIN AI MVP testing!`);
});

module.exports = app;
